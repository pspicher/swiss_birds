{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import Sequential, initializers, optimizers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mute future warning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load metadata\n",
    "data = pd.read_csv(\"data/metadata/selection_sharp.csv\")\n",
    "path = data[\"crop_storage\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First classification pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sets (add header=None for labels since there is no column name and turn to Series)\n",
    "X_tr = pd.read_csv(\"data/features/pool1/X_tr.csv\", index_col=0)\n",
    "y_tr = pd.Series(pd.read_csv(\"data/features/pool1/y_tr.csv\", header=None, index_col=0)[1])\n",
    "X_va = pd.read_csv(\"data/features/pool1/X_va.csv\", index_col=0)\n",
    "y_va = pd.Series(pd.read_csv(\"data/features/pool1/y_va.csv\", header=None, index_col=0)[1])\n",
    "X_te = pd.read_csv(\"data/features/pool1/X_te.csv\", index_col=0)\n",
    "y_te = pd.Series(pd.read_csv(\"data/features/pool1/y_te.csv\", header=None, index_col=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define statistical data type of columns \n",
    "cat_columns = ['Month']\n",
    "num_columns = list(range(300))\n",
    "\n",
    "#define categorical transformer\n",
    "cat_transformer = OneHotEncoder(sparse=False)\n",
    "\n",
    "#define the log transformer\n",
    "log_transformer = FunctionTransformer(np.log1p)\n",
    "\n",
    "#define the column transformer\n",
    "preprocessor = ColumnTransformer([\n",
    "('categorical', cat_transformer, cat_columns),\n",
    "(\"log\", log_transformer, [\"altitude\"]),    \n",
    "(\"scale_log\", StandardScaler(), [\"altitude\"])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the train data and transform\n",
    "X_tr = preprocessor.fit_transform(X_tr)\n",
    "\n",
    "#transform the validation and test data\n",
    "X_va = preprocessor.transform(X_va)\n",
    "X_te = preprocessor.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn labels to float\n",
    "#define classes\n",
    "classes = y_tr.unique()\n",
    "\n",
    "#create an ordinal transformer indicating the 6 classes as categories\n",
    "ordinal_transformer = OrdinalEncoder(categories=[classes])\n",
    "\n",
    "#turn the labels to float\n",
    "y_tr_float = ordinal_transformer.fit_transform(y_tr[:,np.newaxis]).reshape(y_tr.shape[0],)\n",
    "y_va_float = ordinal_transformer.fit_transform(y_va[:,np.newaxis]).reshape(y_va.shape[0],)\n",
    "y_te_float = ordinal_transformer.fit_transform(y_te[:,np.newaxis]).reshape(y_te.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                6340      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 126       \n",
      "=================================================================\n",
      "Total params: 6,466\n",
      "Trainable params: 6,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define number of features\n",
    "n_feat = X_tr.shape[1]\n",
    "\n",
    "#create neural network with one hidden layer\n",
    "nn1 = Sequential()\n",
    "#add hidden layer\n",
    "nn1.add(Dense(20, activation=\"relu\", input_dim=n_feat, kernel_initializer=initializers.VarianceScaling(scale=2.0, seed=0)))\n",
    "#add output layer\n",
    "nn1.add(Dense(6, activation=\"softmax\", kernel_initializer=initializers.VarianceScaling(scale=1.0, seed=0)))\n",
    "# Print network summary\n",
    "nn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model with a stochastic gradient descent as optimizer, crossentropy as loss function and accuracy as metrics\n",
    "nn1.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 664 samples, validate on 285 samples\n",
      "Epoch 1/50\n",
      "664/664 [==============================] - 1s 1ms/step - loss: 1.7502 - acc: 0.3148 - val_loss: 1.3973 - val_acc: 0.4842\n",
      "Epoch 2/50\n",
      "664/664 [==============================] - 0s 128us/step - loss: 1.1536 - acc: 0.6506 - val_loss: 0.9740 - val_acc: 0.7368\n",
      "Epoch 3/50\n",
      "664/664 [==============================] - 0s 131us/step - loss: 0.8028 - acc: 0.7937 - val_loss: 0.7049 - val_acc: 0.8035\n",
      "Epoch 4/50\n",
      "664/664 [==============================] - 0s 118us/step - loss: 0.5826 - acc: 0.8509 - val_loss: 0.5462 - val_acc: 0.8596\n",
      "Epoch 5/50\n",
      "664/664 [==============================] - 0s 122us/step - loss: 0.4563 - acc: 0.8795 - val_loss: 0.4567 - val_acc: 0.8667\n",
      "Epoch 6/50\n",
      "664/664 [==============================] - 0s 139us/step - loss: 0.3773 - acc: 0.8961 - val_loss: 0.4005 - val_acc: 0.8772\n",
      "Epoch 7/50\n",
      "664/664 [==============================] - 0s 148us/step - loss: 0.3251 - acc: 0.9127 - val_loss: 0.3609 - val_acc: 0.8912\n",
      "Epoch 8/50\n",
      "664/664 [==============================] - 0s 158us/step - loss: 0.2869 - acc: 0.9232 - val_loss: 0.3321 - val_acc: 0.9018\n",
      "Epoch 9/50\n",
      "664/664 [==============================] - 0s 185us/step - loss: 0.2579 - acc: 0.9247 - val_loss: 0.3094 - val_acc: 0.9123\n",
      "Epoch 10/50\n",
      "664/664 [==============================] - 0s 178us/step - loss: 0.2344 - acc: 0.9262 - val_loss: 0.2937 - val_acc: 0.9123\n",
      "Epoch 11/50\n",
      "664/664 [==============================] - 0s 171us/step - loss: 0.2152 - acc: 0.9413 - val_loss: 0.2802 - val_acc: 0.9193\n",
      "Epoch 12/50\n",
      "664/664 [==============================] - 0s 169us/step - loss: 0.1987 - acc: 0.9473 - val_loss: 0.2704 - val_acc: 0.9193\n",
      "Epoch 13/50\n",
      "664/664 [==============================] - 0s 155us/step - loss: 0.1850 - acc: 0.9533 - val_loss: 0.2604 - val_acc: 0.9263\n",
      "Epoch 14/50\n",
      "664/664 [==============================] - 0s 167us/step - loss: 0.1723 - acc: 0.9563 - val_loss: 0.2541 - val_acc: 0.9263\n",
      "Epoch 15/50\n",
      "664/664 [==============================] - 0s 164us/step - loss: 0.1618 - acc: 0.9623 - val_loss: 0.2473 - val_acc: 0.9263\n",
      "Epoch 16/50\n",
      "664/664 [==============================] - 0s 151us/step - loss: 0.1522 - acc: 0.9684 - val_loss: 0.2421 - val_acc: 0.9263\n",
      "Epoch 17/50\n",
      "664/664 [==============================] - 0s 157us/step - loss: 0.1434 - acc: 0.9684 - val_loss: 0.2370 - val_acc: 0.9298\n",
      "Epoch 18/50\n",
      "664/664 [==============================] - 0s 141us/step - loss: 0.1357 - acc: 0.9699 - val_loss: 0.2325 - val_acc: 0.9298\n",
      "Epoch 19/50\n",
      "664/664 [==============================] - 0s 165us/step - loss: 0.1288 - acc: 0.9714 - val_loss: 0.2295 - val_acc: 0.9298\n",
      "Epoch 20/50\n",
      "664/664 [==============================] - 0s 126us/step - loss: 0.1222 - acc: 0.9714 - val_loss: 0.2255 - val_acc: 0.9298\n",
      "Epoch 21/50\n",
      "664/664 [==============================] - 0s 125us/step - loss: 0.1158 - acc: 0.9744 - val_loss: 0.2224 - val_acc: 0.9333\n",
      "Epoch 22/50\n",
      "664/664 [==============================] - 0s 121us/step - loss: 0.1101 - acc: 0.9759 - val_loss: 0.2205 - val_acc: 0.9368\n",
      "Epoch 23/50\n",
      "664/664 [==============================] - 0s 149us/step - loss: 0.1049 - acc: 0.9804 - val_loss: 0.2184 - val_acc: 0.9368\n",
      "Epoch 24/50\n",
      "664/664 [==============================] - 0s 121us/step - loss: 0.0998 - acc: 0.9804 - val_loss: 0.2165 - val_acc: 0.9368\n",
      "Epoch 25/50\n",
      "664/664 [==============================] - 0s 122us/step - loss: 0.0955 - acc: 0.9819 - val_loss: 0.2147 - val_acc: 0.9368\n",
      "Epoch 26/50\n",
      "664/664 [==============================] - 0s 142us/step - loss: 0.0913 - acc: 0.9804 - val_loss: 0.2132 - val_acc: 0.9368\n",
      "Epoch 27/50\n",
      "664/664 [==============================] - 0s 144us/step - loss: 0.0875 - acc: 0.9834 - val_loss: 0.2108 - val_acc: 0.9368\n",
      "Epoch 28/50\n",
      "664/664 [==============================] - 0s 120us/step - loss: 0.0837 - acc: 0.9834 - val_loss: 0.2101 - val_acc: 0.9404\n",
      "Epoch 29/50\n",
      "664/664 [==============================] - 0s 117us/step - loss: 0.0802 - acc: 0.9864 - val_loss: 0.2084 - val_acc: 0.9404\n",
      "Epoch 30/50\n",
      "664/664 [==============================] - 0s 117us/step - loss: 0.0772 - acc: 0.9864 - val_loss: 0.2071 - val_acc: 0.9368\n",
      "Epoch 31/50\n",
      "664/664 [==============================] - 0s 127us/step - loss: 0.0741 - acc: 0.9864 - val_loss: 0.2062 - val_acc: 0.9368\n",
      "Epoch 32/50\n",
      "664/664 [==============================] - 0s 125us/step - loss: 0.0713 - acc: 0.9864 - val_loss: 0.2057 - val_acc: 0.9333\n",
      "Epoch 33/50\n",
      "664/664 [==============================] - 0s 123us/step - loss: 0.0685 - acc: 0.9880 - val_loss: 0.2046 - val_acc: 0.9333\n",
      "Epoch 34/50\n",
      "664/664 [==============================] - 0s 129us/step - loss: 0.0661 - acc: 0.9880 - val_loss: 0.2042 - val_acc: 0.9263\n",
      "Epoch 35/50\n",
      "664/664 [==============================] - 0s 124us/step - loss: 0.0634 - acc: 0.9880 - val_loss: 0.2028 - val_acc: 0.9263\n",
      "Epoch 36/50\n",
      "664/664 [==============================] - 0s 125us/step - loss: 0.0613 - acc: 0.9910 - val_loss: 0.2021 - val_acc: 0.9263\n",
      "Epoch 37/50\n",
      "664/664 [==============================] - 0s 124us/step - loss: 0.0591 - acc: 0.9895 - val_loss: 0.2013 - val_acc: 0.9263\n",
      "Epoch 38/50\n",
      "664/664 [==============================] - 0s 119us/step - loss: 0.0571 - acc: 0.9910 - val_loss: 0.2011 - val_acc: 0.9263\n",
      "Epoch 39/50\n",
      "664/664 [==============================] - 0s 126us/step - loss: 0.0553 - acc: 0.9910 - val_loss: 0.2005 - val_acc: 0.9263\n",
      "Epoch 40/50\n",
      "664/664 [==============================] - 0s 126us/step - loss: 0.0534 - acc: 0.9925 - val_loss: 0.2001 - val_acc: 0.9263\n",
      "Epoch 41/50\n",
      "664/664 [==============================] - 0s 117us/step - loss: 0.0517 - acc: 0.9955 - val_loss: 0.2001 - val_acc: 0.9263\n",
      "Epoch 42/50\n",
      "664/664 [==============================] - 0s 124us/step - loss: 0.0500 - acc: 0.9955 - val_loss: 0.1991 - val_acc: 0.9263\n",
      "Epoch 43/50\n",
      "664/664 [==============================] - 0s 128us/step - loss: 0.0485 - acc: 0.9955 - val_loss: 0.1995 - val_acc: 0.9263\n",
      "Epoch 44/50\n",
      "664/664 [==============================] - 0s 125us/step - loss: 0.0470 - acc: 0.9955 - val_loss: 0.1988 - val_acc: 0.9263\n",
      "Epoch 45/50\n",
      "664/664 [==============================] - 0s 128us/step - loss: 0.0455 - acc: 0.9970 - val_loss: 0.1987 - val_acc: 0.9263\n",
      "Epoch 46/50\n",
      "664/664 [==============================] - 0s 124us/step - loss: 0.0442 - acc: 0.9970 - val_loss: 0.1987 - val_acc: 0.9263\n",
      "Epoch 47/50\n",
      "664/664 [==============================] - 0s 121us/step - loss: 0.0429 - acc: 0.9970 - val_loss: 0.1985 - val_acc: 0.9263\n",
      "Epoch 48/50\n",
      "664/664 [==============================] - 0s 124us/step - loss: 0.0416 - acc: 0.9970 - val_loss: 0.1983 - val_acc: 0.9263\n",
      "Epoch 49/50\n",
      "664/664 [==============================] - 0s 124us/step - loss: 0.0405 - acc: 0.9970 - val_loss: 0.1983 - val_acc: 0.9263\n",
      "Epoch 50/50\n",
      "664/664 [==============================] - 0s 125us/step - loss: 0.0393 - acc: 0.9970 - val_loss: 0.1978 - val_acc: 0.9298\n"
     ]
    }
   ],
   "source": [
    "#fit the neural network\n",
    "history_nn1 = nn1.fit(\n",
    "x=X_tr, y=y_tr_float,\n",
    "validation_data=(X_va, y_va_float), batch_size=32, epochs=50,\n",
    "shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 0s 70us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9327731092436975"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute test accuracy\n",
    "(nn1_te_loss1, nn1_te_accuracy1) = nn1.evaluate(X_te, y_te_float, batch_size=32)\n",
    "nn1_te_accuracy1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second classification pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sets (add header=None for labels since there is no column name and turn to Series)\n",
    "X_tr = pd.read_csv(\"data/features/pool2/X_tr.csv\", index_col=0)\n",
    "y_tr = pd.Series(pd.read_csv(\"data/features/pool2/y_tr.csv\", header=None, index_col=0)[1])\n",
    "X_va = pd.read_csv(\"data/features/pool2/X_va.csv\", index_col=0)\n",
    "y_va = pd.Series(pd.read_csv(\"data/features/pool2/y_va.csv\", header=None, index_col=0)[1])\n",
    "X_te = pd.read_csv(\"data/features/pool2/X_te.csv\", index_col=0)\n",
    "y_te = pd.Series(pd.read_csv(\"data/features/pool2/y_te.csv\", header=None, index_col=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define statistical data type of columns \n",
    "cat_columns = ['Month']\n",
    "num_columns = list(range(300))\n",
    "\n",
    "#define categorical transformer\n",
    "cat_transformer = OneHotEncoder(sparse=False)\n",
    "\n",
    "#define the log transformer\n",
    "log_transformer = FunctionTransformer(np.log1p)\n",
    "\n",
    "#define the column transformer\n",
    "preprocessor = ColumnTransformer([\n",
    "('categorical', cat_transformer, cat_columns),\n",
    "(\"log\", log_transformer, [\"altitude\"]),    \n",
    "(\"scale_log\", StandardScaler(), [\"altitude\"])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the train data and transform\n",
    "X_tr = preprocessor.fit_transform(X_tr)\n",
    "\n",
    "#transform the validation and test data\n",
    "X_va = preprocessor.transform(X_va)\n",
    "X_te = preprocessor.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn labels to float\n",
    "#define classes\n",
    "classes = y_tr.unique()\n",
    "\n",
    "#create an ordinal transformer indicating the 6 classes as categories\n",
    "ordinal_transformer = OrdinalEncoder(categories=[classes])\n",
    "\n",
    "#turn the labels to float\n",
    "y_tr_float = ordinal_transformer.fit_transform(y_tr[:,np.newaxis]).reshape(y_tr.shape[0],)\n",
    "y_va_float = ordinal_transformer.fit_transform(y_va[:,np.newaxis]).reshape(y_va.shape[0],)\n",
    "y_te_float = ordinal_transformer.fit_transform(y_te[:,np.newaxis]).reshape(y_te.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 20)                6340      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 126       \n",
      "=================================================================\n",
      "Total params: 6,466\n",
      "Trainable params: 6,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define number of features\n",
    "n_feat = X_tr.shape[1]\n",
    "\n",
    "#create neural network with one hidden layer\n",
    "nn1 = Sequential()\n",
    "#add hidden layer\n",
    "nn1.add(Dense(20, activation=\"relu\", input_dim=n_feat, kernel_initializer=initializers.VarianceScaling(scale=2.0, seed=0)))\n",
    "#add output layer\n",
    "nn1.add(Dense(6, activation=\"softmax\", kernel_initializer=initializers.VarianceScaling(scale=1.0, seed=0)))\n",
    "# Print network summary\n",
    "nn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model with a stochastic gradient descent as optimizer, crossentropy as loss function and accuracy as metrics\n",
    "nn1.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 575 samples, validate on 247 samples\n",
      "Epoch 1/50\n",
      "575/575 [==============================] - 1s 1ms/step - loss: 1.9226 - acc: 0.2817 - val_loss: 1.6567 - val_acc: 0.4291\n",
      "Epoch 2/50\n",
      "575/575 [==============================] - 0s 126us/step - loss: 1.3846 - acc: 0.4922 - val_loss: 1.3180 - val_acc: 0.5587\n",
      "Epoch 3/50\n",
      "575/575 [==============================] - 0s 133us/step - loss: 1.0800 - acc: 0.6139 - val_loss: 1.0915 - val_acc: 0.6154\n",
      "Epoch 4/50\n",
      "575/575 [==============================] - 0s 125us/step - loss: 0.8739 - acc: 0.7009 - val_loss: 0.9318 - val_acc: 0.6559\n",
      "Epoch 5/50\n",
      "575/575 [==============================] - 0s 128us/step - loss: 0.7265 - acc: 0.7739 - val_loss: 0.8127 - val_acc: 0.7166\n",
      "Epoch 6/50\n",
      "575/575 [==============================] - 0s 126us/step - loss: 0.6197 - acc: 0.7983 - val_loss: 0.7231 - val_acc: 0.7530\n",
      "Epoch 7/50\n",
      "575/575 [==============================] - 0s 132us/step - loss: 0.5381 - acc: 0.8452 - val_loss: 0.6503 - val_acc: 0.7773\n",
      "Epoch 8/50\n",
      "575/575 [==============================] - 0s 141us/step - loss: 0.4729 - acc: 0.8748 - val_loss: 0.5941 - val_acc: 0.8016\n",
      "Epoch 9/50\n",
      "575/575 [==============================] - 0s 127us/step - loss: 0.4204 - acc: 0.8887 - val_loss: 0.5485 - val_acc: 0.8421\n",
      "Epoch 10/50\n",
      "575/575 [==============================] - 0s 140us/step - loss: 0.3779 - acc: 0.9026 - val_loss: 0.5138 - val_acc: 0.8421\n",
      "Epoch 11/50\n",
      "575/575 [==============================] - 0s 113us/step - loss: 0.3435 - acc: 0.9148 - val_loss: 0.4849 - val_acc: 0.8623\n",
      "Epoch 12/50\n",
      "575/575 [==============================] - 0s 124us/step - loss: 0.3149 - acc: 0.9165 - val_loss: 0.4627 - val_acc: 0.8704\n",
      "Epoch 13/50\n",
      "575/575 [==============================] - 0s 134us/step - loss: 0.2906 - acc: 0.9235 - val_loss: 0.4430 - val_acc: 0.8704\n",
      "Epoch 14/50\n",
      "575/575 [==============================] - 0s 135us/step - loss: 0.2695 - acc: 0.9322 - val_loss: 0.4238 - val_acc: 0.8866\n",
      "Epoch 15/50\n",
      "575/575 [==============================] - 0s 142us/step - loss: 0.2517 - acc: 0.9322 - val_loss: 0.4126 - val_acc: 0.8866\n",
      "Epoch 16/50\n",
      "575/575 [==============================] - 0s 127us/step - loss: 0.2366 - acc: 0.9357 - val_loss: 0.3992 - val_acc: 0.8947\n",
      "Epoch 17/50\n",
      "575/575 [==============================] - 0s 134us/step - loss: 0.2228 - acc: 0.9374 - val_loss: 0.3894 - val_acc: 0.8988\n",
      "Epoch 18/50\n",
      "575/575 [==============================] - 0s 135us/step - loss: 0.2111 - acc: 0.9478 - val_loss: 0.3802 - val_acc: 0.8988\n",
      "Epoch 19/50\n",
      "575/575 [==============================] - 0s 126us/step - loss: 0.2005 - acc: 0.9530 - val_loss: 0.3728 - val_acc: 0.8988\n",
      "Epoch 20/50\n",
      "575/575 [==============================] - 0s 127us/step - loss: 0.1918 - acc: 0.9513 - val_loss: 0.3656 - val_acc: 0.9069\n",
      "Epoch 21/50\n",
      "575/575 [==============================] - 0s 137us/step - loss: 0.1833 - acc: 0.9530 - val_loss: 0.3605 - val_acc: 0.9028\n",
      "Epoch 22/50\n",
      "575/575 [==============================] - 0s 138us/step - loss: 0.1750 - acc: 0.9583 - val_loss: 0.3547 - val_acc: 0.9109\n",
      "Epoch 23/50\n",
      "575/575 [==============================] - 0s 125us/step - loss: 0.1676 - acc: 0.9617 - val_loss: 0.3521 - val_acc: 0.9069\n",
      "Epoch 24/50\n",
      "575/575 [==============================] - 0s 130us/step - loss: 0.1615 - acc: 0.9652 - val_loss: 0.3479 - val_acc: 0.9069\n",
      "Epoch 25/50\n",
      "575/575 [==============================] - 0s 136us/step - loss: 0.1552 - acc: 0.9652 - val_loss: 0.3418 - val_acc: 0.9109\n",
      "Epoch 26/50\n",
      "575/575 [==============================] - 0s 129us/step - loss: 0.1494 - acc: 0.9704 - val_loss: 0.3387 - val_acc: 0.9109\n",
      "Epoch 27/50\n",
      "575/575 [==============================] - 0s 137us/step - loss: 0.1439 - acc: 0.9739 - val_loss: 0.3352 - val_acc: 0.9109\n",
      "Epoch 28/50\n",
      "575/575 [==============================] - 0s 126us/step - loss: 0.1390 - acc: 0.9739 - val_loss: 0.3338 - val_acc: 0.9109\n",
      "Epoch 29/50\n",
      "575/575 [==============================] - 0s 133us/step - loss: 0.1341 - acc: 0.9739 - val_loss: 0.3317 - val_acc: 0.9109\n",
      "Epoch 30/50\n",
      "575/575 [==============================] - 0s 130us/step - loss: 0.1295 - acc: 0.9757 - val_loss: 0.3287 - val_acc: 0.9150\n",
      "Epoch 31/50\n",
      "575/575 [==============================] - 0s 133us/step - loss: 0.1254 - acc: 0.9757 - val_loss: 0.3275 - val_acc: 0.9150\n",
      "Epoch 32/50\n",
      "575/575 [==============================] - 0s 122us/step - loss: 0.1215 - acc: 0.9774 - val_loss: 0.3243 - val_acc: 0.9190\n",
      "Epoch 33/50\n",
      "575/575 [==============================] - 0s 129us/step - loss: 0.1178 - acc: 0.9774 - val_loss: 0.3231 - val_acc: 0.9190\n",
      "Epoch 34/50\n",
      "575/575 [==============================] - 0s 131us/step - loss: 0.1143 - acc: 0.9757 - val_loss: 0.3209 - val_acc: 0.9190\n",
      "Epoch 35/50\n",
      "575/575 [==============================] - 0s 115us/step - loss: 0.1108 - acc: 0.9791 - val_loss: 0.3192 - val_acc: 0.9190\n",
      "Epoch 36/50\n",
      "575/575 [==============================] - 0s 110us/step - loss: 0.1073 - acc: 0.9791 - val_loss: 0.3185 - val_acc: 0.9190\n",
      "Epoch 37/50\n",
      "575/575 [==============================] - 0s 142us/step - loss: 0.1045 - acc: 0.9791 - val_loss: 0.3176 - val_acc: 0.9190\n",
      "Epoch 38/50\n",
      "575/575 [==============================] - 0s 144us/step - loss: 0.1015 - acc: 0.9809 - val_loss: 0.3169 - val_acc: 0.9190\n",
      "Epoch 39/50\n",
      "575/575 [==============================] - 0s 141us/step - loss: 0.0988 - acc: 0.9809 - val_loss: 0.3162 - val_acc: 0.9190\n",
      "Epoch 40/50\n",
      "575/575 [==============================] - 0s 137us/step - loss: 0.0959 - acc: 0.9826 - val_loss: 0.3145 - val_acc: 0.9190\n",
      "Epoch 41/50\n",
      "575/575 [==============================] - 0s 129us/step - loss: 0.0935 - acc: 0.9809 - val_loss: 0.3134 - val_acc: 0.9190\n",
      "Epoch 42/50\n",
      "575/575 [==============================] - 0s 140us/step - loss: 0.0911 - acc: 0.9809 - val_loss: 0.3131 - val_acc: 0.9190\n",
      "Epoch 43/50\n",
      "575/575 [==============================] - 0s 132us/step - loss: 0.0888 - acc: 0.9826 - val_loss: 0.3126 - val_acc: 0.9150\n",
      "Epoch 44/50\n",
      "575/575 [==============================] - 0s 172us/step - loss: 0.0864 - acc: 0.9809 - val_loss: 0.3117 - val_acc: 0.9150\n",
      "Epoch 45/50\n",
      "575/575 [==============================] - 0s 123us/step - loss: 0.0844 - acc: 0.9843 - val_loss: 0.3118 - val_acc: 0.9150\n",
      "Epoch 46/50\n",
      "575/575 [==============================] - 0s 131us/step - loss: 0.0823 - acc: 0.9826 - val_loss: 0.3122 - val_acc: 0.9109\n",
      "Epoch 47/50\n",
      "575/575 [==============================] - 0s 136us/step - loss: 0.0804 - acc: 0.9861 - val_loss: 0.3118 - val_acc: 0.9109\n",
      "Epoch 48/50\n",
      "575/575 [==============================] - 0s 117us/step - loss: 0.0785 - acc: 0.9878 - val_loss: 0.3105 - val_acc: 0.9109\n",
      "Epoch 49/50\n",
      "575/575 [==============================] - 0s 123us/step - loss: 0.0764 - acc: 0.9878 - val_loss: 0.3094 - val_acc: 0.9109\n",
      "Epoch 50/50\n",
      "575/575 [==============================] - 0s 136us/step - loss: 0.0747 - acc: 0.9861 - val_loss: 0.3099 - val_acc: 0.9109\n"
     ]
    }
   ],
   "source": [
    "#fit the neural network\n",
    "history_nn1 = nn1.fit(\n",
    "x=X_tr, y=y_tr_float,\n",
    "validation_data=(X_va, y_va_float), batch_size=32, epochs=50,\n",
    "shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 85us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9223300959300069"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute test accuracy\n",
    "(nn1_te_loss2, nn1_te_accuracy2) = nn1.evaluate(X_te, y_te_float, batch_size=32)\n",
    "nn1_te_accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First classication pool balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sets (add header=None for labels since there is no column name and turn to Series)\n",
    "X_tr = pd.read_csv(\"data/features/pool1_bal/X_tr.csv\", index_col=0)\n",
    "y_tr = pd.Series(pd.read_csv(\"data/features/pool1_bal/y_tr.csv\", header=None, index_col=0)[1])\n",
    "X_va = pd.read_csv(\"data/features/pool1_bal/X_va.csv\", index_col=0)\n",
    "y_va = pd.Series(pd.read_csv(\"data/features/pool1_bal/y_va.csv\", header=None, index_col=0)[1])\n",
    "X_te = pd.read_csv(\"data/features/pool1_bal/X_te.csv\", index_col=0)\n",
    "y_te = pd.Series(pd.read_csv(\"data/features/pool1_bal/y_te.csv\", header=None, index_col=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define statistical data type of columns \n",
    "cat_columns = ['Month']\n",
    "num_columns = list(range(300))\n",
    "\n",
    "#define categorical transformer\n",
    "cat_transformer = OneHotEncoder(sparse=False)\n",
    "\n",
    "#define the log transformer\n",
    "log_transformer = FunctionTransformer(np.log1p)\n",
    "\n",
    "#define the column transformer\n",
    "preprocessor = ColumnTransformer([\n",
    "('categorical', cat_transformer, cat_columns),\n",
    "(\"log\", log_transformer, [\"altitude\"]),    \n",
    "(\"scale_log\", StandardScaler(), [\"altitude\"])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the train data and transform\n",
    "X_tr = preprocessor.fit_transform(X_tr)\n",
    "\n",
    "#transform the validation and test data\n",
    "X_va = preprocessor.transform(X_va)\n",
    "X_te = preprocessor.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn labels to float\n",
    "#define classes\n",
    "classes = y_tr.unique()\n",
    "\n",
    "#create an ordinal transformer indicating the 6 classes as categories\n",
    "ordinal_transformer = OrdinalEncoder(categories=[classes])\n",
    "\n",
    "#turn the labels to float\n",
    "y_tr_float = ordinal_transformer.fit_transform(y_tr[:,np.newaxis]).reshape(y_tr.shape[0],)\n",
    "y_va_float = ordinal_transformer.fit_transform(y_va[:,np.newaxis]).reshape(y_va.shape[0],)\n",
    "y_te_float = ordinal_transformer.fit_transform(y_te[:,np.newaxis]).reshape(y_te.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 20)                6340      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 126       \n",
      "=================================================================\n",
      "Total params: 6,466\n",
      "Trainable params: 6,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define number of features\n",
    "n_feat = X_tr.shape[1]\n",
    "\n",
    "#create neural network with one hidden layer\n",
    "nn1 = Sequential()\n",
    "#add hidden layer\n",
    "nn1.add(Dense(20, activation=\"relu\", input_dim=n_feat, kernel_initializer=initializers.VarianceScaling(scale=2.0, seed=0)))\n",
    "#add output layer\n",
    "nn1.add(Dense(6, activation=\"softmax\", kernel_initializer=initializers.VarianceScaling(scale=1.0, seed=0)))\n",
    "# Print network summary\n",
    "nn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model with a stochastic gradient descent as optimizer, crossentropy as loss function and accuracy as metrics\n",
    "nn1.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 523 samples, validate on 225 samples\n",
      "Epoch 1/50\n",
      "523/523 [==============================] - 1s 2ms/step - loss: 1.9396 - acc: 0.2524 - val_loss: 1.6531 - val_acc: 0.4000\n",
      "Epoch 2/50\n",
      "523/523 [==============================] - 0s 116us/step - loss: 1.3810 - acc: 0.4990 - val_loss: 1.2653 - val_acc: 0.5956\n",
      "Epoch 3/50\n",
      "523/523 [==============================] - 0s 112us/step - loss: 1.0236 - acc: 0.7094 - val_loss: 0.9929 - val_acc: 0.7111\n",
      "Epoch 4/50\n",
      "523/523 [==============================] - 0s 111us/step - loss: 0.7701 - acc: 0.8050 - val_loss: 0.8024 - val_acc: 0.7556\n",
      "Epoch 5/50\n",
      "523/523 [==============================] - 0s 108us/step - loss: 0.5963 - acc: 0.8719 - val_loss: 0.6699 - val_acc: 0.7867\n",
      "Epoch 6/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.4776 - acc: 0.8929 - val_loss: 0.5818 - val_acc: 0.7911\n",
      "Epoch 7/50\n",
      "523/523 [==============================] - 0s 101us/step - loss: 0.3983 - acc: 0.9120 - val_loss: 0.5219 - val_acc: 0.8044\n",
      "Epoch 8/50\n",
      "523/523 [==============================] - 0s 102us/step - loss: 0.3429 - acc: 0.9197 - val_loss: 0.4771 - val_acc: 0.8267\n",
      "Epoch 9/50\n",
      "523/523 [==============================] - 0s 108us/step - loss: 0.3018 - acc: 0.9293 - val_loss: 0.4424 - val_acc: 0.8356\n",
      "Epoch 10/50\n",
      "523/523 [==============================] - 0s 98us/step - loss: 0.2701 - acc: 0.9312 - val_loss: 0.4162 - val_acc: 0.8489\n",
      "Epoch 11/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.2455 - acc: 0.9388 - val_loss: 0.3962 - val_acc: 0.8533\n",
      "Epoch 12/50\n",
      "523/523 [==============================] - 0s 105us/step - loss: 0.2259 - acc: 0.9407 - val_loss: 0.3784 - val_acc: 0.8622\n",
      "Epoch 13/50\n",
      "523/523 [==============================] - 0s 102us/step - loss: 0.2086 - acc: 0.9407 - val_loss: 0.3648 - val_acc: 0.8622\n",
      "Epoch 14/50\n",
      "523/523 [==============================] - 0s 99us/step - loss: 0.1942 - acc: 0.9522 - val_loss: 0.3523 - val_acc: 0.8711\n",
      "Epoch 15/50\n",
      "523/523 [==============================] - 0s 101us/step - loss: 0.1816 - acc: 0.9541 - val_loss: 0.3413 - val_acc: 0.8756\n",
      "Epoch 16/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.1706 - acc: 0.9618 - val_loss: 0.3334 - val_acc: 0.8756\n",
      "Epoch 17/50\n",
      "523/523 [==============================] - 0s 116us/step - loss: 0.1615 - acc: 0.9637 - val_loss: 0.3273 - val_acc: 0.8844\n",
      "Epoch 18/50\n",
      "523/523 [==============================] - 0s 109us/step - loss: 0.1526 - acc: 0.9656 - val_loss: 0.3222 - val_acc: 0.8889\n",
      "Epoch 19/50\n",
      "523/523 [==============================] - 0s 102us/step - loss: 0.1445 - acc: 0.9656 - val_loss: 0.3153 - val_acc: 0.8889\n",
      "Epoch 20/50\n",
      "523/523 [==============================] - 0s 102us/step - loss: 0.1377 - acc: 0.9656 - val_loss: 0.3105 - val_acc: 0.8933\n",
      "Epoch 21/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.1310 - acc: 0.9713 - val_loss: 0.3058 - val_acc: 0.8933\n",
      "Epoch 22/50\n",
      "523/523 [==============================] - 0s 100us/step - loss: 0.1252 - acc: 0.9713 - val_loss: 0.3007 - val_acc: 0.9067\n",
      "Epoch 23/50\n",
      "523/523 [==============================] - 0s 99us/step - loss: 0.1194 - acc: 0.9751 - val_loss: 0.2959 - val_acc: 0.9111\n",
      "Epoch 24/50\n",
      "523/523 [==============================] - 0s 110us/step - loss: 0.1144 - acc: 0.9771 - val_loss: 0.2929 - val_acc: 0.9111\n",
      "Epoch 25/50\n",
      "523/523 [==============================] - 0s 97us/step - loss: 0.1095 - acc: 0.9751 - val_loss: 0.2897 - val_acc: 0.9111\n",
      "Epoch 26/50\n",
      "523/523 [==============================] - 0s 99us/step - loss: 0.1050 - acc: 0.9809 - val_loss: 0.2863 - val_acc: 0.9111\n",
      "Epoch 27/50\n",
      "523/523 [==============================] - 0s 97us/step - loss: 0.1009 - acc: 0.9828 - val_loss: 0.2828 - val_acc: 0.9111\n",
      "Epoch 28/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.0969 - acc: 0.9828 - val_loss: 0.2800 - val_acc: 0.9111\n",
      "Epoch 29/50\n",
      "523/523 [==============================] - 0s 101us/step - loss: 0.0933 - acc: 0.9828 - val_loss: 0.2781 - val_acc: 0.9111\n",
      "Epoch 30/50\n",
      "523/523 [==============================] - 0s 102us/step - loss: 0.0895 - acc: 0.9847 - val_loss: 0.2760 - val_acc: 0.9111\n",
      "Epoch 31/50\n",
      "523/523 [==============================] - 0s 98us/step - loss: 0.0862 - acc: 0.9847 - val_loss: 0.2739 - val_acc: 0.9156\n",
      "Epoch 32/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.0831 - acc: 0.9847 - val_loss: 0.2718 - val_acc: 0.9156\n",
      "Epoch 33/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.0800 - acc: 0.9847 - val_loss: 0.2725 - val_acc: 0.9156\n",
      "Epoch 34/50\n",
      "523/523 [==============================] - 0s 104us/step - loss: 0.0769 - acc: 0.9847 - val_loss: 0.2694 - val_acc: 0.9156\n",
      "Epoch 35/50\n",
      "523/523 [==============================] - 0s 101us/step - loss: 0.0742 - acc: 0.9866 - val_loss: 0.2676 - val_acc: 0.9156\n",
      "Epoch 36/50\n",
      "523/523 [==============================] - 0s 99us/step - loss: 0.0717 - acc: 0.9885 - val_loss: 0.2655 - val_acc: 0.9156\n",
      "Epoch 37/50\n",
      "523/523 [==============================] - 0s 102us/step - loss: 0.0693 - acc: 0.9885 - val_loss: 0.2639 - val_acc: 0.9156\n",
      "Epoch 38/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.0671 - acc: 0.9904 - val_loss: 0.2634 - val_acc: 0.9156\n",
      "Epoch 39/50\n",
      "523/523 [==============================] - 0s 98us/step - loss: 0.0649 - acc: 0.9904 - val_loss: 0.2624 - val_acc: 0.9156\n",
      "Epoch 40/50\n",
      "523/523 [==============================] - 0s 98us/step - loss: 0.0628 - acc: 0.9924 - val_loss: 0.2614 - val_acc: 0.9156\n",
      "Epoch 41/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.0609 - acc: 0.9943 - val_loss: 0.2599 - val_acc: 0.9156\n",
      "Epoch 42/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.0592 - acc: 0.9943 - val_loss: 0.2587 - val_acc: 0.9156\n",
      "Epoch 43/50\n",
      "523/523 [==============================] - 0s 107us/step - loss: 0.0574 - acc: 0.9943 - val_loss: 0.2581 - val_acc: 0.9156\n",
      "Epoch 44/50\n",
      "523/523 [==============================] - 0s 100us/step - loss: 0.0557 - acc: 0.9943 - val_loss: 0.2575 - val_acc: 0.9156\n",
      "Epoch 45/50\n",
      "523/523 [==============================] - 0s 104us/step - loss: 0.0542 - acc: 0.9943 - val_loss: 0.2565 - val_acc: 0.9156\n",
      "Epoch 46/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.0526 - acc: 0.9943 - val_loss: 0.2547 - val_acc: 0.9244\n",
      "Epoch 47/50\n",
      "523/523 [==============================] - 0s 100us/step - loss: 0.0511 - acc: 0.9943 - val_loss: 0.2542 - val_acc: 0.9244\n",
      "Epoch 48/50\n",
      "523/523 [==============================] - 0s 104us/step - loss: 0.0497 - acc: 0.9943 - val_loss: 0.2532 - val_acc: 0.9244\n",
      "Epoch 49/50\n",
      "523/523 [==============================] - 0s 106us/step - loss: 0.0484 - acc: 0.9943 - val_loss: 0.2526 - val_acc: 0.9244\n",
      "Epoch 50/50\n",
      "523/523 [==============================] - 0s 103us/step - loss: 0.0471 - acc: 0.9943 - val_loss: 0.2525 - val_acc: 0.9244\n"
     ]
    }
   ],
   "source": [
    "#fit the neural network\n",
    "history_nn1 = nn1.fit(\n",
    "x=X_tr, y=y_tr_float,\n",
    "validation_data=(X_va, y_va_float), batch_size=32, epochs=50,\n",
    "shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 0s 76us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9358288747741577"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute test accuracy\n",
    "(nn1_te_loss1_bal, nn1_te_accuracy1_bal) = nn1.evaluate(X_te, y_te_float, batch_size=32)\n",
    "nn1_te_accuracy1_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second classification pool balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sets (add header=None for labels since there is no column name and turn to Series)\n",
    "X_tr = pd.read_csv(\"data/features/pool2_bal/X_tr.csv\", index_col=0)\n",
    "y_tr = pd.Series(pd.read_csv(\"data/features/pool2_bal/y_tr.csv\", header=None, index_col=0)[1])\n",
    "X_va = pd.read_csv(\"data/features/pool2_bal/X_va.csv\", index_col=0)\n",
    "y_va = pd.Series(pd.read_csv(\"data/features/pool2_bal/y_va.csv\", header=None, index_col=0)[1])\n",
    "X_te = pd.read_csv(\"data/features/pool2_bal/X_te.csv\", index_col=0)\n",
    "y_te = pd.Series(pd.read_csv(\"data/features/pool2_bal/y_te.csv\", header=None, index_col=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define statistical data type of columns \n",
    "cat_columns = ['Month']\n",
    "num_columns = list(range(300))\n",
    "\n",
    "#define categorical transformer\n",
    "cat_transformer = OneHotEncoder(sparse=False)\n",
    "\n",
    "#define the log transformer\n",
    "log_transformer = FunctionTransformer(np.log1p)\n",
    "\n",
    "#define the column transformer\n",
    "preprocessor = ColumnTransformer([\n",
    "('categorical', cat_transformer, cat_columns),\n",
    "(\"log\", log_transformer, [\"altitude\"]),    \n",
    "(\"scale_log\", StandardScaler(), [\"altitude\"])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the train data and transform\n",
    "X_tr = preprocessor.fit_transform(X_tr)\n",
    "\n",
    "#transform the validation and test data\n",
    "X_va = preprocessor.transform(X_va)\n",
    "X_te = preprocessor.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn labels to float\n",
    "#define classes\n",
    "classes = y_tr.unique()\n",
    "\n",
    "#create an ordinal transformer indicating the 6 classes as categories\n",
    "ordinal_transformer = OrdinalEncoder(categories=[classes])\n",
    "\n",
    "#turn the labels to float\n",
    "y_tr_float = ordinal_transformer.fit_transform(y_tr[:,np.newaxis]).reshape(y_tr.shape[0],)\n",
    "y_va_float = ordinal_transformer.fit_transform(y_va[:,np.newaxis]).reshape(y_va.shape[0],)\n",
    "y_te_float = ordinal_transformer.fit_transform(y_te[:,np.newaxis]).reshape(y_te.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 20)                6340      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 126       \n",
      "=================================================================\n",
      "Total params: 6,466\n",
      "Trainable params: 6,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define number of features\n",
    "n_feat = X_tr.shape[1]\n",
    "\n",
    "#create neural network with one hidden layer\n",
    "nn1 = Sequential()\n",
    "#add hidden layer\n",
    "nn1.add(Dense(20, activation=\"relu\", input_dim=n_feat, kernel_initializer=initializers.VarianceScaling(scale=2.0, seed=0)))\n",
    "#add output layer\n",
    "nn1.add(Dense(6, activation=\"softmax\", kernel_initializer=initializers.VarianceScaling(scale=1.0, seed=0)))\n",
    "# Print network summary\n",
    "nn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model with a stochastic gradient descent as optimizer, crossentropy as loss function and accuracy as metrics\n",
    "nn1.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 204 samples, validate on 88 samples\n",
      "Epoch 1/50\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 1.9066 - acc: 0.2353 - val_loss: 1.5745 - val_acc: 0.3409\n",
      "Epoch 2/50\n",
      "204/204 [==============================] - 0s 122us/step - loss: 1.5814 - acc: 0.3431 - val_loss: 1.3517 - val_acc: 0.5227\n",
      "Epoch 3/50\n",
      "204/204 [==============================] - 0s 142us/step - loss: 1.3447 - acc: 0.5196 - val_loss: 1.1981 - val_acc: 0.5455\n",
      "Epoch 4/50\n",
      "204/204 [==============================] - 0s 147us/step - loss: 1.1653 - acc: 0.5931 - val_loss: 1.0762 - val_acc: 0.5795\n",
      "Epoch 5/50\n",
      "204/204 [==============================] - 0s 132us/step - loss: 1.0216 - acc: 0.6618 - val_loss: 0.9716 - val_acc: 0.6136\n",
      "Epoch 6/50\n",
      "204/204 [==============================] - 0s 138us/step - loss: 0.9015 - acc: 0.7206 - val_loss: 0.8846 - val_acc: 0.6591\n",
      "Epoch 7/50\n",
      "204/204 [==============================] - 0s 123us/step - loss: 0.7998 - acc: 0.7745 - val_loss: 0.8096 - val_acc: 0.7045\n",
      "Epoch 8/50\n",
      "204/204 [==============================] - 0s 142us/step - loss: 0.7168 - acc: 0.8039 - val_loss: 0.7436 - val_acc: 0.7159\n",
      "Epoch 9/50\n",
      "204/204 [==============================] - 0s 136us/step - loss: 0.6458 - acc: 0.8137 - val_loss: 0.6913 - val_acc: 0.7386\n",
      "Epoch 10/50\n",
      "204/204 [==============================] - 0s 121us/step - loss: 0.5875 - acc: 0.8529 - val_loss: 0.6475 - val_acc: 0.7841\n",
      "Epoch 11/50\n",
      "204/204 [==============================] - 0s 151us/step - loss: 0.5377 - acc: 0.8578 - val_loss: 0.6137 - val_acc: 0.8068\n",
      "Epoch 12/50\n",
      "204/204 [==============================] - 0s 154us/step - loss: 0.4950 - acc: 0.9020 - val_loss: 0.5825 - val_acc: 0.8182\n",
      "Epoch 13/50\n",
      "204/204 [==============================] - 0s 130us/step - loss: 0.4551 - acc: 0.9118 - val_loss: 0.5519 - val_acc: 0.8523\n",
      "Epoch 14/50\n",
      "204/204 [==============================] - 0s 139us/step - loss: 0.4240 - acc: 0.9118 - val_loss: 0.5293 - val_acc: 0.8636\n",
      "Epoch 15/50\n",
      "204/204 [==============================] - 0s 126us/step - loss: 0.3944 - acc: 0.9118 - val_loss: 0.5089 - val_acc: 0.8636\n",
      "Epoch 16/50\n",
      "204/204 [==============================] - 0s 146us/step - loss: 0.3682 - acc: 0.9216 - val_loss: 0.4882 - val_acc: 0.8750\n",
      "Epoch 17/50\n",
      "204/204 [==============================] - 0s 129us/step - loss: 0.3461 - acc: 0.9216 - val_loss: 0.4689 - val_acc: 0.8750\n",
      "Epoch 18/50\n",
      "204/204 [==============================] - 0s 135us/step - loss: 0.3265 - acc: 0.9265 - val_loss: 0.4534 - val_acc: 0.8750\n",
      "Epoch 19/50\n",
      "204/204 [==============================] - 0s 135us/step - loss: 0.3089 - acc: 0.9363 - val_loss: 0.4408 - val_acc: 0.8750\n",
      "Epoch 20/50\n",
      "204/204 [==============================] - 0s 146us/step - loss: 0.2929 - acc: 0.9461 - val_loss: 0.4287 - val_acc: 0.8750\n",
      "Epoch 21/50\n",
      "204/204 [==============================] - 0s 132us/step - loss: 0.2803 - acc: 0.9510 - val_loss: 0.4184 - val_acc: 0.8750\n",
      "Epoch 22/50\n",
      "204/204 [==============================] - 0s 139us/step - loss: 0.2654 - acc: 0.9608 - val_loss: 0.4096 - val_acc: 0.8864\n",
      "Epoch 23/50\n",
      "204/204 [==============================] - 0s 123us/step - loss: 0.2518 - acc: 0.9608 - val_loss: 0.4013 - val_acc: 0.8864\n",
      "Epoch 24/50\n",
      "204/204 [==============================] - 0s 151us/step - loss: 0.2418 - acc: 0.9608 - val_loss: 0.3913 - val_acc: 0.8977\n",
      "Epoch 25/50\n",
      "204/204 [==============================] - 0s 134us/step - loss: 0.2308 - acc: 0.9608 - val_loss: 0.3864 - val_acc: 0.8977\n",
      "Epoch 26/50\n",
      "204/204 [==============================] - 0s 155us/step - loss: 0.2210 - acc: 0.9608 - val_loss: 0.3787 - val_acc: 0.8977\n",
      "Epoch 27/50\n",
      "204/204 [==============================] - 0s 135us/step - loss: 0.2132 - acc: 0.9608 - val_loss: 0.3747 - val_acc: 0.8977\n",
      "Epoch 28/50\n",
      "204/204 [==============================] - 0s 146us/step - loss: 0.2027 - acc: 0.9608 - val_loss: 0.3689 - val_acc: 0.8977\n",
      "Epoch 29/50\n",
      "204/204 [==============================] - 0s 130us/step - loss: 0.1956 - acc: 0.9608 - val_loss: 0.3621 - val_acc: 0.8977\n",
      "Epoch 30/50\n",
      "204/204 [==============================] - 0s 134us/step - loss: 0.1890 - acc: 0.9608 - val_loss: 0.3579 - val_acc: 0.8977\n",
      "Epoch 31/50\n",
      "204/204 [==============================] - 0s 123us/step - loss: 0.1806 - acc: 0.9657 - val_loss: 0.3554 - val_acc: 0.9091\n",
      "Epoch 32/50\n",
      "204/204 [==============================] - 0s 134us/step - loss: 0.1741 - acc: 0.9608 - val_loss: 0.3513 - val_acc: 0.8977\n",
      "Epoch 33/50\n",
      "204/204 [==============================] - 0s 147us/step - loss: 0.1685 - acc: 0.9657 - val_loss: 0.3466 - val_acc: 0.8977\n",
      "Epoch 34/50\n",
      "204/204 [==============================] - 0s 124us/step - loss: 0.1618 - acc: 0.9706 - val_loss: 0.3439 - val_acc: 0.8977\n",
      "Epoch 35/50\n",
      "204/204 [==============================] - 0s 151us/step - loss: 0.1569 - acc: 0.9755 - val_loss: 0.3427 - val_acc: 0.8864\n",
      "Epoch 36/50\n",
      "204/204 [==============================] - 0s 151us/step - loss: 0.1514 - acc: 0.9755 - val_loss: 0.3395 - val_acc: 0.8977\n",
      "Epoch 37/50\n",
      "204/204 [==============================] - 0s 135us/step - loss: 0.1469 - acc: 0.9755 - val_loss: 0.3372 - val_acc: 0.8977\n",
      "Epoch 38/50\n",
      "204/204 [==============================] - 0s 139us/step - loss: 0.1426 - acc: 0.9804 - val_loss: 0.3374 - val_acc: 0.8750\n",
      "Epoch 39/50\n",
      "204/204 [==============================] - 0s 126us/step - loss: 0.1382 - acc: 0.9804 - val_loss: 0.3338 - val_acc: 0.8750\n",
      "Epoch 40/50\n",
      "204/204 [==============================] - 0s 162us/step - loss: 0.1334 - acc: 0.9853 - val_loss: 0.3309 - val_acc: 0.8977\n",
      "Epoch 41/50\n",
      "204/204 [==============================] - 0s 136us/step - loss: 0.1297 - acc: 0.9853 - val_loss: 0.3276 - val_acc: 0.8977\n",
      "Epoch 42/50\n",
      "204/204 [==============================] - 0s 136us/step - loss: 0.1258 - acc: 0.9853 - val_loss: 0.3247 - val_acc: 0.8977\n",
      "Epoch 43/50\n",
      "204/204 [==============================] - 0s 131us/step - loss: 0.1223 - acc: 0.9804 - val_loss: 0.3245 - val_acc: 0.8977\n",
      "Epoch 44/50\n",
      "204/204 [==============================] - 0s 118us/step - loss: 0.1189 - acc: 0.9853 - val_loss: 0.3215 - val_acc: 0.8977\n",
      "Epoch 45/50\n",
      "204/204 [==============================] - 0s 140us/step - loss: 0.1153 - acc: 0.9853 - val_loss: 0.3202 - val_acc: 0.8977\n",
      "Epoch 46/50\n",
      "204/204 [==============================] - 0s 124us/step - loss: 0.1122 - acc: 0.9853 - val_loss: 0.3187 - val_acc: 0.8977\n",
      "Epoch 47/50\n",
      "204/204 [==============================] - 0s 159us/step - loss: 0.1081 - acc: 0.9853 - val_loss: 0.3160 - val_acc: 0.8977\n",
      "Epoch 48/50\n",
      "204/204 [==============================] - 0s 161us/step - loss: 0.1047 - acc: 0.9853 - val_loss: 0.3139 - val_acc: 0.8977\n",
      "Epoch 49/50\n",
      "204/204 [==============================] - 0s 136us/step - loss: 0.1018 - acc: 0.9853 - val_loss: 0.3128 - val_acc: 0.8977\n",
      "Epoch 50/50\n",
      "204/204 [==============================] - 0s 132us/step - loss: 0.0990 - acc: 0.9853 - val_loss: 0.3098 - val_acc: 0.9091\n"
     ]
    }
   ],
   "source": [
    "#fit the neural network\n",
    "history_nn1 = nn1.fit(\n",
    "x=X_tr, y=y_tr_float,\n",
    "validation_data=(X_va, y_va_float), batch_size=32, epochs=50,\n",
    "shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 140us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9315068501315705"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute test accuracy\n",
    "(nn1_te_loss2_bal, nn1_te_accuracy2_bal) = nn1.evaluate(X_te, y_te_float, batch_size=32)\n",
    "nn1_te_accuracy2_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neural network Pool 1             0.932773\n",
       "Neural network Pool 2             0.922330\n",
       "Neural network Pool 1 balanced    0.935829\n",
       "Neural network Pool 2 balanced    0.931507\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summarise results\n",
    "nn_results = pd.Series([nn1_te_accuracy1,nn1_te_accuracy2, nn1_te_accuracy1_bal, nn1_te_accuracy2_bal],[\"Neural network Pool 1\",\"Neural network Pool 2\", \"Neural network Pool 1 balanced\",\"Neural network Pool 2 balanced\"])\n",
    "nn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "nn_results.to_csv(\"data/results/nn.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
